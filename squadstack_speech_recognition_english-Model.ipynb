{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy SquadStack Speech Recognition (English) Model Package from AWS Marketplace \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for ap-south-1 is as follows.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meet SquadStack ASR, a groundbreaking speech-to-text solution designed for both technology enthusiasts and business users. This innovative AI model boasts top-notch Word Error Rate (WER) performance, ensuring highly accurate transcriptions. SquadStack ASR also offers breakthrough performance in Hinglish transcription, making it perfect for mixed-language environments. With its swift processing capabilities, SquadStack ASR effectively saves time and enhances productivity. Best of all, our competitively priced solution delivers exceptional value without compromising quality. Embrace the future of speech recognition with SquadStack ASR, where precision, efficiency, and affordability harmoniously cater to the needs of tech-savvy users and businesses alike.\n",
    "\n",
    "This sample notebook shows you how to deploy [SquadStack Speech Recognition (English)]() using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [SquadStack Speech Recognition (English)](). If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "## Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page [SquadStack Speech Recognition (English)]()\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = \"<Customer to specify Model package ARN corresponding to their AWS region>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "import numpy as np\n",
    "import sagemaker as sage\n",
    "\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-ap-south-1-851467480473'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "runtime = boto3.client(\"runtime.sagemaker\")\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"asr-english-telesales\"\n",
    "\n",
    "content_type = \"application/x-recordio-protobuf\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.g4dn.xlarge\"\n",
    ")\n",
    "batch_transform_inference_instance_type = (\n",
    "    \"ml.c5.2xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/input/real-time/english-example.wav'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = 'data/input/real-time/'\n",
    "input_file_name = 'english-example.wav'\n",
    "\n",
    "file_name = os.path.join(input_path, input_file_name)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Add code snippet that shows the payload contents>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/output/real-time/english-example_out.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'data/output/real-time/'\n",
    "output_file_name = os.path.join(\n",
    "    output_path, \n",
    "    input_file_name.replace('.wav', '_out.json').replace('.mp3', '_out.json')\n",
    ")\n",
    "\n",
    "output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"application/json\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name $model_name --body fileb://$file_name --content-type $content_type --region $sagemaker_session.boto_region_name $output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'channels': 1,\n",
       "  'created_at': '2023-05-12 10:04:35.750826',\n",
       "  'device': 'cuda:0',\n",
       "  'model_version': 'ASR_generic-english',\n",
       "  'request_id': 'aaca2787-ace6-4ed5-8341-74caf4b078e1',\n",
       "  'total_duration_sec': 27.0,\n",
       "  'total_runtime_sec': 16.5171},\n",
       " 'results': {'transcription': {'0': \" Today, like this day, I will go to gym after sometime and  After coming from gym, I will have my dinner and After having my dinner I go outside outside of house  and play with stray dogs they're just like my brothers actually and then after coming to home i will go to sleep\"}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(output_file_name, 'r') as f:\n",
    "    output = json.load(f)\n",
    "    \n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total channels: 1\n",
      "Total duration of call: 27.0 sec\n",
      "Total prediction time: 16.5171 sec, on device - cuda:0\n"
     ]
    }
   ],
   "source": [
    "print (\"Total channels: {}\".format(output['metadata']['channels']))\n",
    "print (\"Total duration of call: {} sec\".format(output['metadata']['total_duration_sec']))\n",
    "print (\"Total prediction time: {} sec, on device - {}\".format(\n",
    "    output['metadata']['total_runtime_sec'], output['metadata']['device']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel 0: \" Today, like this day, I will go to gym after sometime and  After coming from gym, I will have my dinner and After having my dinner I go outside outside of house  and play with stray dogs they're just like my brothers actually and then after coming to home i will go to sleep\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in output['results']['transcription'].items():\n",
    "    print ('\\nChannel {}: \"{}\"\\n'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-ap-south-1-851467480473/asr-english-telesales\n"
     ]
    }
   ],
   "source": [
    "# upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"data/input/batch\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: asr-english-telesales-2023-05-12-10-04-37-687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................\u001b[32m2023-05-12T10:11:08.606:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m * Serving Flask app 'api'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/May/2023 10:11:08] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/May/2023 10:11:08] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'api'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/May/2023 10:11:08] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/May/2023 10:11:08] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\n",
      "\u001b[32m2023-05-12T10:11:08.606:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m * Serving Flask app 'api'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/May/2023 10:11:08] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/May/2023 10:11:08] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'api'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/May/2023 10:11:08] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/May/2023 10:11:08] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/May/2023 10:12:38] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/May/2023 10:12:38] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/May/2023 10:12:56] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/May/2023 10:12:56] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the batch-transform job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sagemaker-ap-south-1-851467480473/asr-english-telesales-2023-05-12-10-04-37-687',\n",
       " 'sagemaker-ap-south-1-851467480473',\n",
       " 'asr-english-telesales-2023-05-12-10-04-37-687',\n",
       " 'data/output/batch/')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output is available on following path\n",
    "my_bucket = transformer.output_path.split('/')[2]\n",
    "output_folder = transformer.output_path.split('/')[-1]\n",
    "output_path = 'data/output/batch/'\n",
    "\n",
    "transformer.output_path, bucket, output_folder, output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "S3 Path: s3://sagemaker-ap-south-1-851467480473/asr-english-telesales-2023-05-12-10-04-37-687/english-example.wav.out\n",
      "\n",
      "Total channels: 1\n",
      "Total duration of call: 27.0 sec\n",
      "Total prediction time: 17.9373 sec, on device - cpu\n",
      "\n",
      "Channel 0 - Telesales Expert: \" Today, like this day, I will go to gym after sometime and  After coming from gym, I will have my dinner and After having my dinner I go outside outside of house  and play with stray dogs they're just like my brothers actually and then after coming to home i will go to sleep\"\n",
      "\n",
      "\n",
      "\n",
      "S3 Path: s3://sagemaker-ap-south-1-851467480473/asr-english-telesales-2023-05-12-10-04-37-687/hinglish-example.mp3.out\n",
      "\n",
      "Total channels: 2\n",
      "Total duration of call: 114.4795 sec\n",
      "Total prediction time: 89.6779 sec, on device - cpu\n",
      "\n",
      "Channel 0 - Telesales Expert: \" Hello, good afternoon.  the next lecture.  Okay, so we can also collect details of the work done by the team.  Okay.  okay  Well, I hope you enjoyed this video. Please subscribe and like it.\"\n",
      "\n",
      "\n",
      "Channel 1 - Telesales Expert: \" Huh? Huh?  Huh? I'm back over here.  Huh?  I will decide next year.  No, I don't know what you are saying.  Thank you.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=my_bucket)\n",
    "\n",
    "for content in contents['Contents']:\n",
    "\n",
    "    if output_folder in str(content):\n",
    "        \n",
    "        response = conn.get_object(Bucket=my_bucket, Key=content['Key'])\n",
    "        output = json.loads(response['Body'].read())\n",
    "                \n",
    "        output_file_name = os.path.join(output_path, content['Key'].split('/')[-1])\n",
    "        \n",
    "        with open(output_file_name, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "        \n",
    "        print (\"\\n\\nS3 Path: {}\".format(os.path.join('s3://', my_bucket, content['Key'])))\n",
    "        print (\"\\nTotal channels: {}\".format(output['metadata']['channels']))\n",
    "        print (\"Total duration of call: {} sec\".format(output['metadata']['total_duration_sec']))\n",
    "        print (\"Total prediction time: {} sec, on device - {}\".format(\n",
    "            output['metadata']['total_runtime_sec'], output['metadata']['device']\n",
    "        ))\n",
    "        \n",
    "        for k, v in output['results']['transcription'].items():\n",
    "            print ('\\nChannel {} - Telesales Expert: \"{}\"\\n'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: asr-english-telesales-2023-05-12-10-04-36-919\n"
     ]
    }
   ],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
